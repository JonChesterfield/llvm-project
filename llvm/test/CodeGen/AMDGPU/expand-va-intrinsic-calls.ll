; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt -S --expand-va-intrinsics < %s | FileCheck %s
target datalayout = "e-p:64:64-p1:64:64-p2:32:32-p3:32:32-p4:64:64-p5:32:32-p6:32:32-p7:160:256:256:32-p8:128:128-i64:64-v16:16-v24:32-v32:32-v48:64-v96:128-v192:256-v256:256-v512:512-v1024:1024-v2048:2048-n32:64-S32-A5-G1-ni:7:8"
target triple = "amdgcn-amd-amdhsa"


define hidden void @codegen_for_copy(ptr noundef %x) local_unnamed_addr #0 {
; CHECK-LABEL: @codegen_for_copy(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[X_ADDR:%.*]] = alloca ptr, align 8, addrspace(5)
; CHECK-NEXT:    [[CP:%.*]] = alloca ptr, align 8, addrspace(5)
; CHECK-NEXT:    [[X_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[X_ADDR]] to ptr
; CHECK-NEXT:    [[CP_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[CP]] to ptr
; CHECK-NEXT:    store ptr [[X:%.*]], ptr addrspace(5) [[X_ADDR]], align 8, !tbaa [[TBAA3:![0-9]+]]
; CHECK-NEXT:    call void @llvm.lifetime.start.p5(i64 8, ptr addrspace(5) [[CP]]) #[[ATTR5:[0-9]+]]
; CHECK-NEXT:    call void @llvm.memcpy.inline.p0.p0.i32(ptr [[CP_ASCAST]], ptr [[X_ADDR_ASCAST]], i32 8, i1 false)
; CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr addrspace(5) [[CP]], align 8, !tbaa [[TBAA3]]
; CHECK-NEXT:    call void @wrapped(ptr noundef [[TMP0]]) #[[ATTR6:[0-9]+]]
; CHECK-NEXT:    call void @llvm.lifetime.end.p5(i64 8, ptr addrspace(5) [[CP]]) #[[ATTR5]]
; CHECK-NEXT:    ret void
;
entry:
  %x.addr = alloca ptr, align 8, addrspace(5)
  %cp = alloca ptr, align 8, addrspace(5)
  %x.addr.ascast = addrspacecast ptr addrspace(5) %x.addr to ptr
  %cp.ascast = addrspacecast ptr addrspace(5) %cp to ptr
  store ptr %x, ptr addrspace(5) %x.addr, align 8, !tbaa !4
  call void @llvm.lifetime.start.p5(i64 8, ptr addrspace(5) %cp) #4
  call void @llvm.va_copy(ptr %cp.ascast, ptr nonnull %x.addr.ascast)
  %0 = load ptr, ptr addrspace(5) %cp, align 8, !tbaa !4
  call void @wrapped(ptr noundef %0) #5
  call void @llvm.va_end(ptr %cp.ascast)
  call void @llvm.lifetime.end.p5(i64 8, ptr addrspace(5) %cp) #4
  ret void
}

declare void @llvm.lifetime.start.p5(i64 immarg, ptr addrspace(5) nocapture) #1

declare void @llvm.va_copy(ptr, ptr) #2

declare hidden void @wrapped(ptr noundef) local_unnamed_addr #3

declare void @llvm.va_end(ptr) #2

declare void @llvm.lifetime.end.p5(i64 immarg, ptr addrspace(5) nocapture) #1

define hidden void @single_i32(i32 noundef %x) local_unnamed_addr #0 {
; CHECK-LABEL: @single_i32(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[VARARG_BUFFER:%.*]] = alloca [[VARARG_VALIST_VARARG_7:%.*]], align 4, addrspace(5)
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [[VARARG_VALIST_VARARG_7]], ptr addrspace(5) [[VARARG_BUFFER]], i32 0, i32 0
; CHECK-NEXT:    store i32 [[X:%.*]], ptr addrspace(5) [[TMP0]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[VARARG_BUFFER]] to ptr
; CHECK-NEXT:    call void @vararg.valist(ptr [[TMP1]]) #[[ATTR7:[0-9]+]]
; CHECK-NEXT:    ret void
;
entry:
  tail call void (...) @vararg(i32 noundef %x) #6
  ret void
}

define internal void @vararg(...) unnamed_addr #0 {
; CHECK-LABEL: @vararg(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[VA_LIST:%.*]] = alloca ptr, align 8, addrspace(5)
; CHECK-NEXT:    [[TMP0:%.*]] = addrspacecast ptr addrspace(5) [[VA_LIST]] to ptr
; CHECK-NEXT:    call void @llvm.va_start(ptr [[TMP0]])
; CHECK-NEXT:    tail call void @vararg.valist(ptr [[TMP0]])
; CHECK-NEXT:    ret void
;
entry:
  %va = alloca ptr, align 8, addrspace(5)
  %va.ascast = addrspacecast ptr addrspace(5) %va to ptr
  call void @llvm.lifetime.start.p5(i64 8, ptr addrspace(5) %va) #4
  call void @llvm.va_start(ptr %va.ascast)
  %0 = load ptr, ptr addrspace(5) %va, align 8, !tbaa !4
  call void @wrapped(ptr noundef %0) #5
  call void @llvm.va_end(ptr %va.ascast)
  call void @llvm.lifetime.end.p5(i64 8, ptr addrspace(5) %va) #4
  ret void
}

define hidden void @single_double(double noundef %x) local_unnamed_addr #0 {
; CHECK-LABEL: @single_double(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[VARARG_BUFFER:%.*]] = alloca [[VARARG_VALIST_VARARG_6:%.*]], align 8, addrspace(5)
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [[VARARG_VALIST_VARARG_6]], ptr addrspace(5) [[VARARG_BUFFER]], i32 0, i32 0
; CHECK-NEXT:    store double [[X:%.*]], ptr addrspace(5) [[TMP0]], align 8
; CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[VARARG_BUFFER]] to ptr
; CHECK-NEXT:    call void @vararg.valist(ptr [[TMP1]]) #[[ATTR7]]
; CHECK-NEXT:    ret void
;
entry:
  tail call void (...) @vararg(double noundef %x) #6
  ret void
}

define hidden void @single_float4(<4 x float> noundef %x) local_unnamed_addr #0 {
; CHECK-LABEL: @single_float4(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[VARARG_BUFFER:%.*]] = alloca [[VARARG_VALIST_VARARG_5:%.*]], align 16, addrspace(5)
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [[VARARG_VALIST_VARARG_5]], ptr addrspace(5) [[VARARG_BUFFER]], i32 0, i32 0
; CHECK-NEXT:    store <4 x float> [[X:%.*]], ptr addrspace(5) [[TMP0]], align 16
; CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[VARARG_BUFFER]] to ptr
; CHECK-NEXT:    call void @vararg.valist(ptr [[TMP1]]) #[[ATTR7]]
; CHECK-NEXT:    ret void
;
entry:
  tail call void (...) @vararg(<4 x float> noundef %x) #6
  ret void
}

define hidden void @i32_double(i32 noundef %x, double noundef %y) local_unnamed_addr #0 {
; CHECK-LABEL: @i32_double(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[VARARG_BUFFER:%.*]] = alloca [[VARARG_VALIST_VARARG_4:%.*]], align 8, addrspace(5)
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [[VARARG_VALIST_VARARG_4]], ptr addrspace(5) [[VARARG_BUFFER]], i32 0, i32 0
; CHECK-NEXT:    store i32 [[X:%.*]], ptr addrspace(5) [[TMP0]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr inbounds [[VARARG_VALIST_VARARG_4]], ptr addrspace(5) [[VARARG_BUFFER]], i32 0, i32 2
; CHECK-NEXT:    store double [[Y:%.*]], ptr addrspace(5) [[TMP1]], align 8
; CHECK-NEXT:    [[TMP2:%.*]] = addrspacecast ptr addrspace(5) [[VARARG_BUFFER]] to ptr
; CHECK-NEXT:    call void @vararg.valist(ptr [[TMP2]]) #[[ATTR7]]
; CHECK-NEXT:    ret void
;
entry:
  tail call void (...) @vararg(i32 noundef %x, double noundef %y) #6
  ret void
}

define hidden void @double_i32(double noundef %x, i32 noundef %y) local_unnamed_addr #0 {
; CHECK-LABEL: @double_i32(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[VARARG_BUFFER:%.*]] = alloca [[VARARG_VALIST_VARARG_3:%.*]], align 8, addrspace(5)
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [[VARARG_VALIST_VARARG_3]], ptr addrspace(5) [[VARARG_BUFFER]], i32 0, i32 0
; CHECK-NEXT:    store double [[X:%.*]], ptr addrspace(5) [[TMP0]], align 8
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr inbounds [[VARARG_VALIST_VARARG_3]], ptr addrspace(5) [[VARARG_BUFFER]], i32 0, i32 1
; CHECK-NEXT:    store i32 [[Y:%.*]], ptr addrspace(5) [[TMP1]], align 4
; CHECK-NEXT:    [[TMP2:%.*]] = addrspacecast ptr addrspace(5) [[VARARG_BUFFER]] to ptr
; CHECK-NEXT:    call void @vararg.valist(ptr [[TMP2]]) #[[ATTR7]]
; CHECK-NEXT:    ret void
;
entry:
  tail call void (...) @vararg(double noundef %x, i32 noundef %y) #6
  ret void
}

define hidden void @i32_float4(i32 noundef %x, <4 x float> noundef %y) local_unnamed_addr #0 {
; CHECK-LABEL: @i32_float4(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[VARARG_BUFFER:%.*]] = alloca [[VARARG_VALIST_VARARG_2:%.*]], align 16, addrspace(5)
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [[VARARG_VALIST_VARARG_2]], ptr addrspace(5) [[VARARG_BUFFER]], i32 0, i32 0
; CHECK-NEXT:    store i32 [[X:%.*]], ptr addrspace(5) [[TMP0]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr inbounds [[VARARG_VALIST_VARARG_2]], ptr addrspace(5) [[VARARG_BUFFER]], i32 0, i32 2
; CHECK-NEXT:    store <4 x float> [[Y:%.*]], ptr addrspace(5) [[TMP1]], align 16
; CHECK-NEXT:    [[TMP2:%.*]] = addrspacecast ptr addrspace(5) [[VARARG_BUFFER]] to ptr
; CHECK-NEXT:    call void @vararg.valist(ptr [[TMP2]]) #[[ATTR7]]
; CHECK-NEXT:    ret void
;
entry:
  tail call void (...) @vararg(i32 noundef %x, <4 x float> noundef %y) #6
  ret void
}

define hidden void @float4_i32(<4 x float> noundef %x, i32 noundef %y) local_unnamed_addr #0 {
; CHECK-LABEL: @float4_i32(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[VARARG_BUFFER:%.*]] = alloca [[VARARG_VALIST_VARARG_1:%.*]], align 16, addrspace(5)
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [[VARARG_VALIST_VARARG_1]], ptr addrspace(5) [[VARARG_BUFFER]], i32 0, i32 0
; CHECK-NEXT:    store <4 x float> [[X:%.*]], ptr addrspace(5) [[TMP0]], align 16
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr inbounds [[VARARG_VALIST_VARARG_1]], ptr addrspace(5) [[VARARG_BUFFER]], i32 0, i32 1
; CHECK-NEXT:    store i32 [[Y:%.*]], ptr addrspace(5) [[TMP1]], align 4
; CHECK-NEXT:    [[TMP2:%.*]] = addrspacecast ptr addrspace(5) [[VARARG_BUFFER]] to ptr
; CHECK-NEXT:    call void @vararg.valist(ptr [[TMP2]]) #[[ATTR7]]
; CHECK-NEXT:    ret void
;
entry:
  tail call void (...) @vararg(<4 x float> noundef %x, i32 noundef %y) #6
  ret void
}

define hidden void @i32_libcS(i32 noundef %x, i8 %y.coerce0, i16 %y.coerce1, i32 %y.coerce2, i64 %y.coerce3, float %y.coerce4, double %y.coerce5) local_unnamed_addr #0 {
; CHECK-LABEL: @i32_libcS(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[VARARG_BUFFER:%.*]] = alloca [[VARARG_VALIST_VARARG_0:%.*]], align 8, addrspace(5)
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [[VARARG_VALIST_VARARG_0]], ptr addrspace(5) [[VARARG_BUFFER]], i32 0, i32 0
; CHECK-NEXT:    store i32 [[X:%.*]], ptr addrspace(5) [[TMP0]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr inbounds [[VARARG_VALIST_VARARG_0]], ptr addrspace(5) [[VARARG_BUFFER]], i32 0, i32 1
; CHECK-NEXT:    store i8 [[Y_COERCE0:%.*]], ptr addrspace(5) [[TMP1]], align 1
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr inbounds [[VARARG_VALIST_VARARG_0]], ptr addrspace(5) [[VARARG_BUFFER]], i32 0, i32 3
; CHECK-NEXT:    store i16 [[Y_COERCE1:%.*]], ptr addrspace(5) [[TMP2]], align 2
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [[VARARG_VALIST_VARARG_0]], ptr addrspace(5) [[VARARG_BUFFER]], i32 0, i32 5
; CHECK-NEXT:    store i32 [[Y_COERCE2:%.*]], ptr addrspace(5) [[TMP3]], align 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds [[VARARG_VALIST_VARARG_0]], ptr addrspace(5) [[VARARG_BUFFER]], i32 0, i32 6
; CHECK-NEXT:    store i64 [[Y_COERCE3:%.*]], ptr addrspace(5) [[TMP4]], align 8
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds [[VARARG_VALIST_VARARG_0]], ptr addrspace(5) [[VARARG_BUFFER]], i32 0, i32 7
; CHECK-NEXT:    store float [[Y_COERCE4:%.*]], ptr addrspace(5) [[TMP5]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds [[VARARG_VALIST_VARARG_0]], ptr addrspace(5) [[VARARG_BUFFER]], i32 0, i32 9
; CHECK-NEXT:    store double [[Y_COERCE5:%.*]], ptr addrspace(5) [[TMP6]], align 8
; CHECK-NEXT:    [[TMP7:%.*]] = addrspacecast ptr addrspace(5) [[VARARG_BUFFER]] to ptr
; CHECK-NEXT:    call void @vararg.valist(ptr [[TMP7]]) #[[ATTR7]]
; CHECK-NEXT:    ret void
;
entry:
  tail call void (...) @vararg(i32 noundef %x, i8 %y.coerce0, i16 %y.coerce1, i32 %y.coerce2, i64 %y.coerce3, float %y.coerce4, double %y.coerce5) #6
  ret void
}

define hidden void @libcS_i32(i8 %x.coerce0, i16 %x.coerce1, i32 %x.coerce2, i64 %x.coerce3, float %x.coerce4, double %x.coerce5, i32 noundef %y) local_unnamed_addr #0 {
; CHECK-LABEL: @libcS_i32(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[VARARG_BUFFER:%.*]] = alloca [[VARARG_VALIST_VARARG:%.*]], align 8, addrspace(5)
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [[VARARG_VALIST_VARARG]], ptr addrspace(5) [[VARARG_BUFFER]], i32 0, i32 0
; CHECK-NEXT:    store i8 [[X_COERCE0:%.*]], ptr addrspace(5) [[TMP0]], align 1
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr inbounds [[VARARG_VALIST_VARARG]], ptr addrspace(5) [[VARARG_BUFFER]], i32 0, i32 2
; CHECK-NEXT:    store i16 [[X_COERCE1:%.*]], ptr addrspace(5) [[TMP1]], align 2
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr inbounds [[VARARG_VALIST_VARARG]], ptr addrspace(5) [[VARARG_BUFFER]], i32 0, i32 4
; CHECK-NEXT:    store i32 [[X_COERCE2:%.*]], ptr addrspace(5) [[TMP2]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [[VARARG_VALIST_VARARG]], ptr addrspace(5) [[VARARG_BUFFER]], i32 0, i32 6
; CHECK-NEXT:    store i64 [[X_COERCE3:%.*]], ptr addrspace(5) [[TMP3]], align 8
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds [[VARARG_VALIST_VARARG]], ptr addrspace(5) [[VARARG_BUFFER]], i32 0, i32 7
; CHECK-NEXT:    store float [[X_COERCE4:%.*]], ptr addrspace(5) [[TMP4]], align 4
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds [[VARARG_VALIST_VARARG]], ptr addrspace(5) [[VARARG_BUFFER]], i32 0, i32 9
; CHECK-NEXT:    store double [[X_COERCE5:%.*]], ptr addrspace(5) [[TMP5]], align 8
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds [[VARARG_VALIST_VARARG]], ptr addrspace(5) [[VARARG_BUFFER]], i32 0, i32 10
; CHECK-NEXT:    store i32 [[Y:%.*]], ptr addrspace(5) [[TMP6]], align 4
; CHECK-NEXT:    [[TMP7:%.*]] = addrspacecast ptr addrspace(5) [[VARARG_BUFFER]] to ptr
; CHECK-NEXT:    call void @vararg.valist(ptr [[TMP7]]) #[[ATTR7]]
; CHECK-NEXT:    ret void
;
entry:
  tail call void (...) @vararg(i8 %x.coerce0, i16 %x.coerce1, i32 %x.coerce2, i64 %x.coerce3, float %x.coerce4, double %x.coerce5, i32 noundef %y) #6
  ret void
}

declare void @llvm.va_start(ptr) #2

attributes #0 = { nounwind "no-builtins" "no-trapping-math"="true" "stack-protector-buffer-size"="8" }
attributes #1 = { mustprogress nocallback nofree nosync nounwind willreturn memory(argmem: readwrite) }
attributes #2 = { mustprogress nocallback nofree nosync nounwind willreturn }
attributes #3 = { "no-builtins" "no-trapping-math"="true" "stack-protector-buffer-size"="8" }
attributes #4 = { nounwind }
attributes #5 = { nobuiltin nounwind "no-builtins" }
attributes #6 = { nobuiltin "no-builtins" }

!llvm.module.flags = !{!0, !1, !2}

!0 = !{i32 1, !"amdgpu_code_object_version", i32 400}
!1 = !{i32 1, !"wchar_size", i32 4}
!2 = !{i32 8, !"PIC Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any pointer", !6, i64 0}
!6 = !{!"omnipotent char", !7, i64 0}
!7 = !{!"Simple C/C++ TBAA"}
